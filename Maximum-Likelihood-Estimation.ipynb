{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate a toy classification problem dataset for the cartesian coordinate system with two classes (K=2).\n",
    "    - Pick two random cluster center coordinates.\n",
    "    - For each cluster center, generate 40 data points (samples) by adding random noise values to cluster center values.\n",
    "    - Store dataset X along with ground truth label values for each sample.\n",
    "    - Shuffle the dataset (randomize the order of samples in your dataset).\n",
    "    - Separate your dataset X into training and test sets\n",
    "2. Implement multivariate classification using maximum likelihood using your training set.\n",
    "3. Report performance of your algorithm using your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pick two random cluster center coordinates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2): 'class1', (2, 3): 'class2'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_lables =(\"class1\" , \"class2\")\n",
    "centers_dict = {}\n",
    "center1 = (1 , 2)\n",
    "center2 = (2 , 3)\n",
    "centers_dict[center1] = class_lables[0]\n",
    "centers_dict[center2] = class_lables[1]\n",
    "centers_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**generate 40 data points (samples) by adding random noise values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 40\n",
    "np.random.seed(0)\n",
    "point1_X = np.round(np.random.uniform(center1[0]-1 , center1[0]+1,N),3)\n",
    "point2_X = np.round(np.random.uniform(center2[0]-1 , center2[0]+1,N),3)\n",
    "\n",
    "point1_Y = np.round(np.random.uniform(center1[1]-1 , center1[1]+1,N),3)\n",
    "point2_Y = np.round(np.random.uniform(center2[1]-1 , center2[1]+1,N),3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Store dataset X along with ground truth label values for each sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for index in range(N):    \n",
    "    dataset.append([point1_X[index] , point1_Y[index] , class_lables[0]])\n",
    "    dataset.append([point2_X[index] , point2_Y[index] , class_lables[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separate your dataset X into training and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_set = dataset[:train_size]\n",
    "test_set = dataset[train_size+1:] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate classification using maximum likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_covariance_matrix(dataset , mean_vector): \n",
    "    col_len = dataset.shape[1]\n",
    "    result = np.zeros((col_len, col_len)) \n",
    "    for item  in dataset:        \n",
    "        variance = np.matrix(item - mean_vector)\n",
    "        temp = np.dot(np.transpose(variance) , variance)\n",
    "        result += temp\n",
    "    \n",
    "    return (result / (len(dataset) - 1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.29958924 -0.0759681 ]\n",
      " [-0.0759681   0.32641181]]\n"
     ]
    }
   ],
   "source": [
    "dataset_class1 =  np.array([[ x[0],x[1]] for x in train_set if x[2]== \"class1\"])\n",
    "mean_class1 = dataset_class1.mean(axis= 0)\n",
    "sigma_mat1 = cal_covariance_matrix(dataset_class1, mean_class1)\n",
    "prior1 =   np.mean([i[1] for i in dataset_class1])\n",
    "\n",
    "dataset_class2 =  np.array([[ x[0],x[1]] for x in train_set if x[2]== \"class2\"])   \n",
    "mean_class2 = dataset_class2.mean(axis= 0)\n",
    "sigma_mat2 = cal_covariance_matrix(dataset_class2, mean_class2)   \n",
    "prior2 = np.mean([i[1] for i in dataset_class2])\n",
    "\n",
    "print(sigma_mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminate_func(x,y,d, mean_class, sigma_mat , prior):\n",
    "    first_term = -d/2 * math.log( math.pi * 2)\n",
    "    \n",
    "    determinant_sigma_mat = np.linalg.det(sigma_mat)\n",
    "    second_term = 0.5 * math.log(determinant_sigma_mat) \n",
    "    \n",
    "    mean_item = [x-mean_class[0] , y-mean_class[1]]\n",
    "    mean_item_transpose = np.transpose(mean_item)\n",
    "    inverted_sigma_mat = np.linalg.inv(sigma_mat)\n",
    "    \n",
    "\n",
    "    third_term =  1/2 * np.dot(np.dot(mean_item, inverted_sigma_mat) , mean_item_transpose)\n",
    "    result = first_term - second_term - third_term + math.log(prior)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disc1:-2.14 , disc2:-6.98 , class1 , x:1.665 , y:1.04\n",
      "disc1:-0.37 , disc2:-1.98 , class1 , x:0.923 , y:2.47\n",
      "disc1:-5.08 , disc2:-2.38 , class2 , x:2.953 , y:2.299\n",
      "disc1:-1.34 , disc2:0.17 , class2 , x:1.489 , y:2.863\n",
      "disc1:-3.23 , disc2:-0.04 , class2 , x:2.313 , y:2.872\n",
      "disc1:-0.53 , disc2:-0.81 , class2 , x:1.204 , y:2.597\n",
      "disc1:-0.44 , disc2:-4.82 , class1 , x:1.292 , y:1.531\n",
      "disc1:-3.24 , disc2:-0.09 , class2 , x:2.334 , y:2.848\n",
      "disc1:-2.3 , disc2:0.18 , class2 , x:1.323 , y:3.182\n",
      "disc1:-1.33 , disc2:0.22 , class2 , x:1.592 , y:2.814\n",
      "disc1:-0.02 , disc2:-1.95 , class1 , x:1.28 , y:2.152\n",
      "disc1:-1.6 , disc2:0.31 , class1 , x:1.561 , y:2.924\n",
      "disc1:-2.39 , disc2:0.46 , class2 , x:1.874 , y:3.003\n",
      "disc1:-1.95 , disc2:0.36 , class2 , x:1.877 , y:2.858\n",
      "disc1:-5.37 , disc2:-0.26 , class2 , x:1.318 , y:3.793\n",
      "--------------------result--------------------\n",
      "13 correct classification of total 15\n"
     ]
    }
   ],
   "source": [
    "d = 2\n",
    "num_of_correct_classification = 0\n",
    "for test in test_set:\n",
    "    cls = test[2]\n",
    "    discriminant_1 = np.round( discriminate_func(test[0],test[1],d, mean_class1, sigma_mat1 , prior1), 2)\n",
    "    discriminant_2 = np.round( discriminate_func(test[0],test[1],d, mean_class2, sigma_mat2 , prior2) ,2)\n",
    "\n",
    "    if discriminant_1 > discriminant_2 and cls == \"class1\":\n",
    "        num_of_correct_classification += 1\n",
    "    elif discriminant_1 < discriminant_2 and cls == \"class2\":\n",
    "        num_of_correct_classification += 1\n",
    "        \n",
    "    print(\"disc1:{} , disc2:{} , {} , x:{} , y:{}\".format(discriminant_1 , discriminant_2 ,cls,test[0],test[1] ))\n",
    "\n",
    "print(\"{}result{}\".format(\"-\" *20 , \"-\" *20))\n",
    "print('{} correct classification of total {}'.format( num_of_correct_classification , len(test_set)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
